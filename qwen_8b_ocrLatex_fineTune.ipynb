{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/wizardoftrap/llm-notebooks/blob/main/qwen_8b_ocrLatex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "gHOo69QJji2P",
    "outputId": "d3487694-44f9-4cf7-d4f3-062ab6bc639f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.12.8-py3-none-any.whl.metadata (65 kB)\n",
      "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/65.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting unsloth_zoo>=2025.12.6 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.12.6-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from unsloth) (25.0)\n",
      "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.24.0+cu126)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unsloth) (2.0.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.9.5)\n",
      "Collecting tyro (from unsloth)\n",
      "  Downloading tyro-1.0.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from unsloth) (5.29.5)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Downloading xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth)\n",
      "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (3.5.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.2.1)\n",
      "Collecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth)\n",
      "  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (1.12.0)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.18.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.36.0)\n",
      "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth) (0.36.0)\n",
      "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3 in /usr/local/lib/python3.12/dist-packages (from unsloth) (4.57.3)\n",
      "Collecting trl!=0.19.0,<=0.24.0,>=0.18.2 (from unsloth)\n",
      "  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.34.1->unsloth) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.20.0)\n",
      "Collecting pyarrow>=21.0.0 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.32.4)\n",
      "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.4.0->unsloth) (1.11.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (0.22.1)\n",
      "Collecting torchao>=0.13.0 (from unsloth_zoo>=2025.12.6->unsloth)\n",
      "  Downloading torchao-0.15.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.12.6->unsloth)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.12.6->unsloth) (11.3.0)\n",
      "Collecting msgspec (from unsloth_zoo>=2025.12.6->unsloth)\n",
      "  Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting torch>=2.4.0 (from unsloth)\n",
      "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.10.2.21->torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.7.1.2->torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cufft-cu12==11.3.0.4->torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton>=3.0.0 (from unsloth)\n",
      "  Downloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth) (8.7.0)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision (from unsloth)\n",
      "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (0.17.0)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth) (4.4.4)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.12.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.17.0)\n",
      "Downloading unsloth-2025.12.8-py3-none-any.whl (376 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m376.1/376.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-4.3.0-py3-none-any.whl (506 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.24.0-py3-none-any.whl (423 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unsloth_zoo-2025.12.6-py3-none-any.whl (289 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl (122.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m577.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.5.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m910.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-1.0.3-py3-none-any.whl (180 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchao-0.15.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (224 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchao, triton, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, tyro, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch, datasets, xformers, torchvision, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo, unsloth\n",
      "  Attempting uninstall: torchao\n",
      "    Found existing installation: torchao 0.10.0\n",
      "    Uninstalling torchao-0.10.0:\n",
      "      Successfully uninstalled torchao-0.10.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.5.0\n",
      "    Uninstalling triton-3.5.0:\n",
      "      Successfully uninstalled triton-3.5.0\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 18.1.0\n",
      "    Uninstalling pyarrow-18.1.0:\n",
      "      Successfully uninstalled pyarrow-18.1.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
      "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
      "  Attempting uninstall: nvidia-cufile-cu12\n",
      "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
      "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
      "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.9.0+cu126\n",
      "    Uninstalling torch-2.9.0+cu126:\n",
      "      Successfully uninstalled torch-2.9.0+cu126\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 4.0.0\n",
      "    Uninstalling datasets-4.0.0:\n",
      "      Successfully uninstalled datasets-4.0.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.24.0+cu126\n",
      "    Uninstalling torchvision-0.24.0+cu126:\n",
      "      Successfully uninstalled torchvision-0.24.0+cu126\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bitsandbytes-0.49.0 cut_cross_entropy-25.1.1 datasets-4.3.0 msgspec-0.20.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 pyarrow-22.0.0 torch-2.9.1 torchao-0.15.0 torchvision-0.24.1 triton-3.5.1 trl-0.24.0 tyro-1.0.3 unsloth-2025.12.8 unsloth_zoo-2025.12.6 xformers-0.0.33.post2\n",
      "Collecting transformers==4.57.1\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (2025.11.12)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m125.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.57.3\n",
      "    Uninstalling transformers-4.57.3:\n",
      "      Successfully uninstalled transformers-4.57.3\n",
      "Successfully installed transformers-4.57.1\n",
      "Collecting trl==0.22.2\n",
      "  Downloading trl-0.22.2-py3-none-any.whl.metadata (11 kB)\n",
      "Downloading trl-0.22.2-py3-none-any.whl (544 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m544.8/544.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: trl\n",
      "  Attempting uninstall: trl\n",
      "    Found existing installation: trl 0.24.0\n",
      "    Uninstalling trl-0.24.0:\n",
      "      Successfully uninstalled trl-0.24.0\n",
      "Successfully installed trl-0.22.2\n"
     ]
    }
   ],
   "source": [
    "!pip install unsloth\n",
    "!pip install transformers==4.57.1\n",
    "!pip install --no-deps trl==0.22.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXl0sPvdi6Kh",
    "outputId": "c3d35b3f-adc5-4e3f-b2b1-a7cd2e0e7b40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from unsloth import FastVisionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569,
     "referenced_widgets": [
      "d483b04d99634238928e39c34ce7eda6",
      "5f13aa9e02e34b0f9d0cdf6750c6c13b",
      "fec0e71df8fa4ff6a87b73e1c3de613f",
      "2e79d440c8bb4db3a2b950041f723430",
      "51ab32245aec444fa459be0b47b2f98f",
      "a2c45cf4923249079460a0bae2ac5318",
      "85820f0bae344eec83dd2448e7ac6315",
      "103209a0cb2b4cc3b1d852ee6133b1c1",
      "3466b97328804c53875b8e4355f5d979",
      "c1dd75313adf4318b33caa05bd3b832e",
      "91190a943c084619971eee7a66f066bd",
      "8badec33847241dcaf77c616e2f0803f",
      "c3c89f6fdf9f46419194ccd33db6b5f7",
      "93b2e1e0da014e6f950d16bfac12091d",
      "a70b9df30233401a91f8913fd82b1a3a",
      "6306aeede771412e9d14fcba16d229b2",
      "5100fc8fd4d94a4a9d795c66b7f1b9a7",
      "9cbfe4be5f5442e4920b2c6d7969789e",
      "805ac93e9db94ef683b8d495f7f30b81",
      "e262e6078b1a405f92bf526664e36925",
      "9c0df3746e1747178722199834957cdf",
      "e3c67a282a7e45369d344fc0c3558fda",
      "5bca4bc46162434c97efbdc01c9d091e",
      "d146bd5ab22f45b7aef5da1fe2ee61ea",
      "2827e7b69ca540b1bad7f25a06bc086c",
      "bf473d2d33094853a18410c40ac85ef1",
      "ce8090ebb7644b399de24fa6e5b12446",
      "5bf3cb1feec540eeb995efbabdd98825",
      "3c15aa60beec48d0a7b71a9871368a31",
      "a23e10b8822d46c7be4b86611e6aac1b",
      "8af46a244aff4ef38faed1cd6aa017b8",
      "daf156be113040d68d8fce383bde3205",
      "307889ea54bf4fdd8b219c304233b681",
      "8b150ccb4b7d46898c1924393eb35254",
      "b9fcd7fe6c404ccfacf04a7261a29a60",
      "2c40b7f216564bc6878829829578e1eb",
      "40df71699a004395bee7033990f29618",
      "358557e4f9364e92b557d029902c2d92",
      "e54e57e6b782404395ad42deaa1c8176",
      "a4f0099c2f4544dc984735d56ccff673",
      "786b179f8d854aaca462967d77306e66",
      "e52bc2ba01a84e3a9f0421cb52b84882",
      "f4a527fedd3440fd981bc9c9ab7fa5e2",
      "fa196f020cf242058c087e0e0823e433",
      "590e281be9ef4b078ace0f46025f7845",
      "1af18dd29bf341798b6d8476905fcb2c",
      "90730d9c93c14630a1a0a2fa8aa53985",
      "f613d7bee870466390a723af565abf4f",
      "d34b6662ea69426890afd44f7502899a",
      "20d0ef664d6e40f99496a184a1dd6a7b",
      "3ac1c60d87ec4b03a261342016e88938",
      "b02659b89a2347ddb798305b23124967",
      "25b23b91ad6b4c6f8cc4941bc36255bd",
      "69d77871beaa4b79948ffa354b7f5e12",
      "2f26166bcb7f46dfbd91afe2b4e189f4",
      "65d4697b323f450e9f33c6649400076a",
      "21f393cbe2c54fb0ba9f7bb878b5b7cd",
      "6714ec2d8de146a38ea482b7d54eaf48",
      "a379ee8233294f5daf51f56e25519c9f",
      "394337180aa445ce9064d0d4255e4774",
      "07bfa5d7b7904958b182de707631f7a6",
      "d95fb176969b44be8649f9926fcd049b",
      "5364a6a5acba48e2ab030508d4c7b25f",
      "34bab87769394622b000c950a0f231f5",
      "11e9cf1ebd604b7f8c867a06a2aedafa",
      "9f7396150ec44c68a174c068b27262e5",
      "c2c04758e92b4dc7aea0270db4ce1ee5",
      "8a782e478a534519a2574856e07b18cb",
      "4cadd236cfd14dc3819c5654d8840441",
      "68d884cfd5784d50ad239157915a1462",
      "3fd414ef8716426d8ce978753b25a88b",
      "0620820624af4389ba5794a9a9097502",
      "55f7f1e5577e417fb4da63b46c1180d2",
      "33f0e50cdb9f4f248ebe68da2dd27b74",
      "11ef9bc43508493d858223b0dd96175f",
      "03d3a2f63b7e4e34899ed4dc9399f1df",
      "5e385f78a6a740f18c0ef0649f15c965",
      "a8889321e93e42cfad5e035bfeb28bf9",
      "0caa99a2051a4e60848dcaa81acc5e89",
      "1501e086f19744049689614a12d59fe0",
      "4dfaf7a599cd4f2fae121cd441e533f9",
      "a5ba6ff44cb5411090254bb8ba1a503e",
      "4846b3a145b74af1b2f9162162358496",
      "6210fbed59cd42fb93e3676644d3e69c",
      "50e3ae8c26a5403e94e05c1c44db4cc6",
      "b59dd5ec4ecf49f69720c323f478040a",
      "c6137c54a11d4943a899f1bca560005a",
      "622a5bc75819497892264eb4fcbb6ad8",
      "60e1867f78e8422bac93b7ef2368ea21",
      "f50b2ae94a544f46b441d2e31861860c",
      "db505227e4bf4336a80d6168b9136b3b",
      "24fd8f4ca92844c491d214afd9d2d634",
      "3e3782a286b84b739de31762aa8de50d",
      "f3d4ca9fbc02499cb9c79808d827364e",
      "6de9658b9e4f4da4bfe496be5ce0483b",
      "38c120e370d24c2b8f29b11b5b96fe2d",
      "32f916f519cd4bb9be61762062c6909f",
      "0a466eddca2d4afc9490af5cd94b0519",
      "7dc9e01a053f44ddaa553e402a3b30eb",
      "2ec135f75d314fe1a12095501d9f60a4",
      "8d6971c3ed9e4b41b6c7e29a80d428ec",
      "6a3b92ba2e5748729ab41f31d9beb4fa",
      "d3d44577251b40c2bba668dba6f54d6b",
      "021f0a38350d4582a05767eb1a6b5a00",
      "be79dc300fee4fb698518d693f3447fa",
      "b2591b2e70f842f58061d4a7adf65b35",
      "53acd0e5a54f4a60be1b18422dee37cd",
      "19d64461a6494bd3bfb9d384fd73f80d",
      "46cfc502fd33488ca2451820f025c592",
      "2a45e86268bf49c18e824c14a69e2517",
      "65382210ce044ac2bc526aa24c80af6d",
      "eb2ff5b8ad76436d968c679362875f42",
      "d4862c10fe7b4dad99f783ece62bab70",
      "6ebed870012d41149a42d1e0ded9d2ec",
      "fd776327d40046cd9c0c254a7908183d",
      "a57e26e51e684b4e88eda6ddaf12fd41",
      "f3e7c20d033e4fc4ace56bdba5ec463a",
      "72ed791e0c4c43d1b050ceabe8f51442",
      "cafddfd4ee584352af80f227ef42d0a9",
      "452bcbdc2bb54bff9e908ae7698a0d88",
      "f27cb870cf394785a023e90da13e1289",
      "b88d0c91ef294645b1717fc30e94897a",
      "55f42787acef4fd98d80b0457379484f",
      "6c35c54fcaec4ae1aba78470ffc66397",
      "ac39bbc02f71418a8282e6b7c5d01c77",
      "9da8d1ebe5494b79b372c22f78295b49",
      "1c34f93565044c2ebface2466e2a47a7",
      "c14113bd926b40648c986c0982819772",
      "38fb203595b3447991b14db5f96b9199",
      "72f7fe65a3d94ef1884c3dfc71370da7",
      "414886e655d541eb93fd55f932df3aee",
      "6946d42488e74fbbadaf4c51e36b5025",
      "bdf4932dbe92466a81526ca458feade8",
      "f441fa1ea13b435393e3928cd2dbe721",
      "4392156420ab42fa952211cdb6894e06",
      "550010c62eb84851ac9f687fe1dc57f0",
      "6e8f9111a9b4408a95a9ab6042849d43",
      "8b029de40a4f4da693f8d24b46ea62bf",
      "0599a66ad3f84a2d8238124c167f253a",
      "d9129e840a86494d9f5324773b3c9845",
      "e4fa6d9b326447c0a773fc687b1f6459",
      "2f9fe6218d38447496904d067febe863",
      "6d98efdf9f4c448a87ea57c278277180",
      "c0bdacaf54e84a5793dfcbd63f858ea4",
      "2e9832338f6642d0890e6314a6b9a3c7",
      "67ce047e00254d30a44b631de723980f",
      "41b0072b19904625a3abed5c8aec8337",
      "d889a70072c04b168f2ace5be96a6f96",
      "b2bbf07d688a48d7b88b24d3319854d7",
      "530b5d32dfad4a32b3ae68c4044e0b4b",
      "2490b4d8827345f99195b07cecc5d89d",
      "ae9e3d2f1248401bb900a39e849bac6a",
      "8fae6059e86e4f4ab5f63d369f1e355e",
      "c85d96ff1001473199848273336c0f22"
     ]
    },
    "id": "AkrzOsytk-XE",
    "outputId": "2827ff11-4c28-48df-8dfc-dc5e22618718"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.12.8: Fast Qwen3_Vl patching. Transformers: 4.57.1.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d483b04d99634238928e39c34ce7eda6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8badec33847241dcaf77c616e2f0803f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bca4bc46162434c97efbdc01c9d091e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.72G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b150ccb4b7d46898c1924393eb35254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590e281be9ef4b078ace0f46025f7845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/213 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d4697b323f450e9f33c6649400076a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/782 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c04758e92b4dc7aea0270db4ce1ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8889321e93e42cfad5e035bfeb28bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e1867f78e8422bac93b7ef2368ea21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec135f75d314fe1a12095501d9f60a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65382210ce044ac2bc526aa24c80af6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88d0c91ef294645b1717fc30e94897a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf4932dbe92466a81526ca458feade8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0bdacaf54e84a5793dfcbd63f858ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "video_preprocessor_config.json:   0%|          | 0.00/817 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer=FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Qwen3-VL-8B-Instruct-unsloth-bnb-4bit\",\n",
    "    load_in_4bit=True,\n",
    "    use_gradient_checkpointing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9r1tLeiQlU2O"
   },
   "outputs": [],
   "source": [
    "model=FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.0,\n",
    "    finetune_vision_layers=True,\n",
    "    finetune_language_layers=True,\n",
    "    finetune_attention_modules=True,\n",
    "    finetune_mlp_modules=True,\n",
    "    random_state=3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "cf14f927f56a4725ba276824e1ebd8e2",
      "e14b01c323fa4adc9e0a1e61c3af74e9",
      "08f8cf1c63074f9ebf00b47070cfd732",
      "12ebbbe9586a458ea1db118d8b7d074c",
      "ef120c115aa6463093ea54c5c0add259",
      "2afc89fef9164e15b9748eb0b7433f03",
      "a41a67f8a71a4ac8a17d16ae12ff9a02",
      "d7e0c9e97ba84f50814ac75f0e1e28bb",
      "6ed91072631a4bd49a7293c98996c8ef",
      "c7e494cd48b642508cc40b6ffe149697",
      "788be6fb1aee4801986df82a142f42c3",
      "8cf2341c69de4a2f881f2311d9e227f8",
      "d0201b0592e94d1e88318029d2228947",
      "291eef1ecdcf45d08897abed48408049",
      "5f0d8d88eff84d65b0c8bd184e87b8b6",
      "d34cf52587c14c2c88e3e6db5453fa95",
      "0dd0ca26c3aa4f10a08dae6a522cae6b",
      "f864188377df49b3bcabdeccc56b703e",
      "a04e23a5a00d41468385560e50ad627f",
      "1c748cc744dc48d5acda8ee8fc17ccdb",
      "eb999c0b491143ffa542d68295a63200",
      "a98e06224f364372b6fa073a7ff831bd",
      "310846fcccb148a18039b278a4de5c3c",
      "3bdbb2c9042e4fd6ba3e5eb254a82256",
      "8367727fc59642f6abb9fcd1be4fafbc",
      "4ac1bae42d11446e8bbd66c0dde0a232",
      "28e1714575c14d2b90d26f9aac78835d",
      "39917cde7c3048b89c1e5fb5bd1f1e7f",
      "de48bc3a71c6461e8a22b3922faa505d",
      "ac11cb725d7240d6bdc098951f4c88df",
      "30959421de4d418297e779ecd47e0200",
      "0b012a5d2dcf4e8c9c4a7b85909e51eb",
      "1e247cb93599468998377474536cf0cf",
      "fb2ef6e160814dd0ade3bd28a77f1308",
      "8af4e80e2c784d30bce027a0004edd38",
      "688720368c574e009c2d2a6839c0c90d",
      "06ac0fa354f44617a6f5227e9b288909",
      "51c06bd67245482d862c6e751b53805c",
      "f0fbf196baf64e7789c523c4f96e650d",
      "2fbce19eb7f64e38b23adbb97ff35f36",
      "a381593abd654c0b900dcedf22b7b431",
      "3b77874b8ab0438989783713ae785c48",
      "670b84acf75c419baf47d40f93193152",
      "0756a70b19ee4449bb651d511c7ce176",
      "c380e5c63265421789cc968e52ddc3f8",
      "4edbca8c94d74bab942c6d608c0d56ba",
      "51eedd2b7c37483aad2ed1caa4abc50d",
      "afa986f5fc0f4313b340f3f2acf42adc",
      "9e10d49f38664823a5c00b162c0d8b56",
      "bc6932c0551a415b8b502b81624f6434",
      "7fb46066535c41e28c1cca763f10f56c",
      "7c0321e5c6684082993d217b4e95b76c",
      "25a3f256b57d406a8744060e8edb02de",
      "9361e311b1454074bce471ff686e076e",
      "bf4376dc01e6497a90bdc8f4848492fd"
     ]
    },
    "collapsed": true,
    "id": "0scpfoSbmD3W",
    "outputId": "652c82cf-2c28-460e-e73a-351480c093b6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf14f927f56a4725ba276824e1ebd8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/519 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf2341c69de4a2f881f2311d9e227f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/344M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310846fcccb148a18039b278a4de5c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/38.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2ef6e160814dd0ade3bd28a77f1308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/68686 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c380e5c63265421789cc968e52ddc3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7632 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"unsloth/LaTeX_OCR\", split = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Am97pXycsURE",
    "outputId": "3f097a73-7682-41d2-8e84-4f1d25fcde7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'text'],\n",
       "    num_rows: 68686\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "OiksqzvZs7Ps",
    "outputId": "8d158580-7f53-4ff0-fffc-04200ec10a5a"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAyAHgDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3+iiqOo6ta6Wtsblmzc3EdtEqLuLO5wB9OpJ7AGgC3M0iwu0KK8oUlEZtoY9gTg4+uDXMW/je2ufCtvrCWU5uLi4+xpYqQZBc7ynlk9Bggkk8ADNWbnxFcXvhkal4csW1Ca4kMVssn7tM7yvmOTz5YwWyOSMY61g+G/Cl3p+o6xpGsxf2lp18YtSN06qqG7PEwCjBX5lDgDoD160AdR4a11PEeiR6ikDQbnkQxMwYqVcrnI7HGR7EVr1T03SrDR7T7LptnDaW+9n8uFAq5JyeBUNzrun2muWOjSzYvr2OSSGMDOVQDcT6dePXn0NAGlRWBovjHSdf1GWysGmdkh+0LI0RWOWPeyB0buCytg98ZHFb9ABRRRQAUUUUAFFFFABRRRQBx/jPVHtNQ0uyn1N9K0udJpbq7iyJWKbNkSNg4ZixOANxCYHWszSfB+o61oWgza5qmrLNDKb2WOebE6ybWWMBlxswrHIHc16GQD1ooA5y30G58OaLbab4WS0SKNjkX8kj8dsEc+30FVzceL1uFt2n8NidlLLEXm3EDuB1xXV15P4tsdLHiNLGDVV/tN9Vg1O5up2Tdp8YwAiNjcWfACx89SeB1AO7g1DUtLsLu98SSWEcEShlazWViB3yCCSemAK86dNSj8c+GfEmqRWZW/vGkCRBzPbwvbskaOSMBF3c4x8zH1r2LtSNnacde3NAHI6HpnhfTdbik0+8le78qSyiie5eRVSFvmRVPAEe7b7Zx1NdHpWqWmtabFf2LSNby52GSJ4m4JByrgEcg9RXJeE/Ad1otzp+o32sXEt1BBKrW6BREDM/myLnG5hvJOSecJ6c9zQAUUUUAFFFFABRRRQAUUUUAFFFFABWS/hfw/JqY1N9D01r8SCUXTWqGUOOjbsZzwOfataigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAP//Z\n",
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=120x50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[3][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "avPTFjcAtFYt",
    "outputId": "d97e779b-2e7f-446e-bedc-ac55b895798e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\\\sigma ^ { \\\\mu } \\\\frac { \\\\lambda ^ { a } } { 2 } A _ { \\\\mu } ^ { a } .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[3][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "AM3_8Oewsf9T",
    "outputId": "252aceb6-7f4e-484e-fd3c-62e090fa030e"
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sigma ^ { \\mu } \\frac { \\lambda ^ { a } } { 2 } A _ { \\mu } ^ { a } .$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "latex = dataset[3][\"text\"]\n",
    "display(Math(latex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yu4h-hZtICt"
   },
   "outputs": [],
   "source": [
    "instruction = \"Write the LaTeX representation for this image.\"\n",
    "\n",
    "def convert_to_conversation(sample):\n",
    "    conversation = [\n",
    "        { \"role\": \"user\",\n",
    "          \"content\" : [\n",
    "            {\"type\" : \"text\",  \"text\"  : instruction},\n",
    "            {\"type\" : \"image\", \"image\" : sample[\"image\"]} ]\n",
    "        },\n",
    "        { \"role\" : \"assistant\",\n",
    "          \"content\" : [\n",
    "            {\"type\" : \"text\",  \"text\"  : sample[\"text\"]} ]\n",
    "        },\n",
    "    ]\n",
    "    return { \"messages\" : conversation }\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DD9gdFyEtXSt"
   },
   "outputs": [],
   "source": [
    "converted_dataset = [convert_to_conversation(sample) for sample in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "OX3aZsXLtaI9",
    "outputId": "9106ee28-9ccf-4445-d182-285366dfd743"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'Write the LaTeX representation for this image.'},\n",
       "    {'type': 'image',\n",
       "     'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=120x50>}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': '\\\\sigma ^ { \\\\mu } \\\\frac { \\\\lambda ^ { a } } { 2 } A _ { \\\\mu } ^ { a } .'}]}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "MflPB_g1tl-M",
    "outputId": "095cac66-2e4d-4ec1-eeba-5d19e1100042"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen3VLForConditionalGeneration(\n",
       "      (model): Qwen3VLModel(\n",
       "        (visual): Qwen3VLVisionModel(\n",
       "          (patch_embed): Qwen3VLVisionPatchEmbed(\n",
       "            (proj): Conv3d(3, 1152, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
       "          )\n",
       "          (pos_embed): Embedding(2304, 1152)\n",
       "          (rotary_pos_emb): Qwen3VLVisionRotaryEmbedding()\n",
       "          (blocks): ModuleList(\n",
       "            (0-26): 27 x Qwen3VLVisionBlock(\n",
       "              (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "              (attn): Qwen3VLVisionAttention(\n",
       "                (qkv): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1152, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=3456, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1152, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1152, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "              (mlp): Qwen3VLVisionMLP(\n",
       "                (linear_fc1): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=1152, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4304, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (linear_fc2): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4304, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1152, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): GELUTanh()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (merger): Qwen3VLVisionPatchMerger(\n",
       "            (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "            (linear_fc1): Linear(in_features=4608, out_features=4608, bias=True)\n",
       "            (act_fn): GELU(approximate='none')\n",
       "            (linear_fc2): Linear(in_features=4608, out_features=4096, bias=True)\n",
       "          )\n",
       "          (deepstack_merger_list): ModuleList(\n",
       "            (0-2): 3 x Qwen3VLVisionPatchMerger(\n",
       "              (norm): LayerNorm((4608,), eps=1e-06, elementwise_affine=True)\n",
       "              (linear_fc1): Linear(in_features=4608, out_features=4608, bias=True)\n",
       "              (act_fn): GELU(approximate='none')\n",
       "              (linear_fc2): Linear(in_features=4608, out_features=4096, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (language_model): Qwen3VLTextModel(\n",
       "          (embed_tokens): Embedding(151936, 4096)\n",
       "          (layers): ModuleList(\n",
       "            (0-5): 6 x Qwen3VLTextDecoderLayer(\n",
       "              (self_attn): Qwen3VLTextAttention(\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
       "                (k_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
       "              )\n",
       "              (mlp): Qwen3VLTextMLP(\n",
       "                (gate_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (up_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (down_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=12288, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): SiLUActivation()\n",
       "              )\n",
       "              (input_layernorm): Qwen3VLTextRMSNorm((4096,), eps=1e-06)\n",
       "              (post_attention_layernorm): Qwen3VLTextRMSNorm((4096,), eps=1e-06)\n",
       "            )\n",
       "            (6): Qwen3VLTextDecoderLayer(\n",
       "              (self_attn): Qwen3VLTextAttention(\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
       "                (k_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
       "              )\n",
       "              (mlp): Qwen3VLTextMLP(\n",
       "                (gate_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (up_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (down_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=12288, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): SiLUActivation()\n",
       "              )\n",
       "              (input_layernorm): Qwen3VLTextRMSNorm((4096,), eps=1e-06)\n",
       "              (post_attention_layernorm): Qwen3VLTextRMSNorm((4096,), eps=1e-06)\n",
       "            )\n",
       "            (7-15): 9 x Qwen3VLTextDecoderLayer(\n",
       "              (self_attn): Qwen3VLTextAttention(\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
       "                (k_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
       "              )\n",
       "              (mlp): Qwen3VLTextMLP(\n",
       "                (gate_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (up_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (down_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=12288, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): SiLUActivation()\n",
       "              )\n",
       "              (input_layernorm): Qwen3VLTextRMSNorm((4096,), eps=1e-06)\n",
       "              (post_attention_layernorm): Qwen3VLTextRMSNorm((4096,), eps=1e-06)\n",
       "            )\n",
       "            (16): Qwen3VLTextDecoderLayer(\n",
       "              (self_attn): Qwen3VLTextAttention(\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
       "                (k_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
       "              )\n",
       "              (mlp): Qwen3VLTextMLP(\n",
       "                (gate_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (up_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (down_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=12288, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): SiLUActivation()\n",
       "              )\n",
       "              (input_layernorm): Qwen3VLTextRMSNorm((4096,), eps=1e-06)\n",
       "              (post_attention_layernorm): Qwen3VLTextRMSNorm((4096,), eps=1e-06)\n",
       "            )\n",
       "            (17-34): 18 x Qwen3VLTextDecoderLayer(\n",
       "              (self_attn): Qwen3VLTextAttention(\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
       "                (k_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
       "              )\n",
       "              (mlp): Qwen3VLTextMLP(\n",
       "                (gate_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (up_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (down_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=12288, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): SiLUActivation()\n",
       "              )\n",
       "              (input_layernorm): Qwen3VLTextRMSNorm((4096,), eps=1e-06)\n",
       "              (post_attention_layernorm): Qwen3VLTextRMSNorm((4096,), eps=1e-06)\n",
       "            )\n",
       "            (35): Qwen3VLTextDecoderLayer(\n",
       "              (self_attn): Qwen3VLTextAttention(\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (q_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
       "                (k_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
       "              )\n",
       "              (mlp): Qwen3VLTextMLP(\n",
       "                (gate_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (up_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (down_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=12288, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Identity()\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=12288, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (act_fn): SiLUActivation()\n",
       "              )\n",
       "              (input_layernorm): Qwen3VLTextRMSNorm((4096,), eps=1e-06)\n",
       "              (post_attention_layernorm): Qwen3VLTextRMSNorm((4096,), eps=1e-06)\n",
       "            )\n",
       "          )\n",
       "          (norm): Qwen3VLTextRMSNorm((4096,), eps=1e-06)\n",
       "          (rotary_emb): Qwen3VLTextRotaryEmbedding()\n",
       "        )\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastVisionModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ctY4lyUtvcL",
    "outputId": "811badc7-415b-4bca-8bb1-6d9614fd9288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " $$\\sigma ^ { \\mu } \\frac { \\lambda ^ { a } } { 2 } A _ { \\mu } ^ { a } .$$<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "image = dataset[3][\"image\"]\n",
    "instruction = \"Write the LaTeX representation for this image.\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": instruction}\n",
    "    ]}\n",
    "]\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\n",
    "inputs = tokenizer(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens = False,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XnEf989BuT48",
    "outputId": "4b587e02-66c6-4105-f9b6-83203fa6dcd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Model does not have a default image size - using 512\n"
     ]
    }
   ],
   "source": [
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "FastVisionModel.for_training(model) # Enable for training!\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = UnslothVisionDataCollator(model, tokenizer), # Must use!\n",
    "    train_dataset = converted_dataset,\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        max_steps = 30,\n",
    "        num_train_epochs = 1, # Set this instead of max_steps for full training runs\n",
    "        learning_rate = 2e-4,\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.001,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\",     # For Weights and Biases\n",
    "\n",
    "        # You MUST put the below items for vision finetuning:\n",
    "        remove_unused_columns = False,\n",
    "        dataset_text_field = \"\",\n",
    "        dataset_kwargs = {\"skip_prepare_dataset\": True},\n",
    "        max_length = 2048,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "kSCUmyBevkvd",
    "outputId": "d0c306f6-2073-44e1-cc91-0f4581955cef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 68,686 | Num Epochs = 1 | Total steps = 30\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 51,346,944 of 8,818,470,640 (0.58% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 03:09, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.252200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.494300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.438800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.062100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.881500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.913700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.691600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.460700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.263500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.279900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.218100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.225100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.175100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.174500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.148100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.141500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.110500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.094100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.110400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.056100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.093200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.053900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.107600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.088300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.040900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.206300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.058500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.126800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9TIIOoYwVP0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b464bc8bfe9147e1915ff2a8a39db199",
      "96e15eb73cac456ba8361dc5469017fc",
      "724752201b654ababbe9bb1b70ee09ad",
      "8a9be4ddc66642599b2be09b2084289c",
      "cf3e8c0937714f1ab6968d3f29bc3525",
      "52c42216991a40a3ab3bd7e2760add97",
      "4bee0784b1954e348906e8b5f21ca6f9",
      "ef7fc127128d4b8e86f1d7b355f68939",
      "dd3c0cc46caf4eec874d475f79fd7e6d",
      "332e2cda61644bcc89e6476a602aa83e",
      "151c932251d14103bdedbdb57e3dcb82",
      "f70fb7d3ad994227a3e58c9ac9141c9f",
      "d95270f0763f43d1bdd712f983a542ea",
      "41614c02f6fd4e719bfd95159b9ecb98",
      "1d6d61694881429c843e81745784a624",
      "871a5ffcd5324bb997361bccabe69a25",
      "db564406c3fb4baf8a9bbc619c429e63",
      "ed957f790e28482b92d5ac10e93b76ab",
      "f6917135e3ef4cd5be3e0260b5dc81d7",
      "97da804d837847a3b0b1729d89a89c0d",
      "e5b0d77cf2d845518c50a5a1e3520f1e",
      "3f78399e326e4a878ce0528708418c8d",
      "0308da58442d4dd3a4b9941933cd3018",
      "ccb36aeadfe54ed6a1172d2ec2ce5992",
      "f550116b059d40e687a0b411620f3595",
      "849bb33628744a9d974d44339ee22a33",
      "6892faa7a8aa4c9d945fd07ad2f1fd6a",
      "3f7e517e52244702bd2fdae4c185a362",
      "a625acb2673644609cfe6d30f6d3ce1e",
      "979eed2a55014c0bbcf186893e9c889d",
      "e3a4e41664254984b9df66166f979f4a",
      "876ee47a702d40e2b6f0fdedd79f2e32",
      "fa55a19cf4fe420ea639c3439c57cbac",
      "c90ed7ab5ae84e9399783a13613b3fb6",
      "c3426b1dc8b644a3b6cdaac958b9266a",
      "8fbdad2cd8d74f76802bacce4e042912",
      "d474b70e72094b22b43eb78b6cc603d1",
      "3d94bbc8e4cf421f807f8fa3ed11db97",
      "17de870edb184173bdd64b63a356e330",
      "43effd7326bb4bba8aff70e24bfc5c15",
      "bb67c906b8d74ddaa75f9ca9b2253e3f",
      "6f3cba5dd1fd447b90cafb764ead5a56",
      "4457523fd72346309bf2d68a890eed74",
      "37946f3e7ff8403d953b64f0a01dae2e",
      "b6b977af7d5242cfb984183af85c8dd6",
      "1e8fe6a538e74a508c99794233854ec1",
      "bc6da0fb9c1c478a8ba509d19a5ea7af",
      "0a1595c545b6481a836aa36a537100b7",
      "9f6f96b2d8ca411cbc1aad4f8747d8fc",
      "dadd22fd802b4ab5b6243e6abd6aa25b",
      "e42d08af36294094b23593d8c44d63e2",
      "caeca69f08bb4220b259d2be809a8022",
      "515b5454ffc9467080fb89792428f1c8",
      "5a4ba17efd384d6ca41f4ed55ff5afcb",
      "f250c615d9c2453c8955812c2b75add5",
      "754c9941cf1e4764899dcf360e1002ba",
      "eb87a32e35bd4c51802e0335a637ee97",
      "86f33ed3b1364448b0de96f110da4ebc",
      "495e6f21bdef4cfaada0eb48f2fdc2e6",
      "678412323a6b46dd9dcf16c6b690379e",
      "35c7f8923762470c9e0e75d42de6e739",
      "d889cba47322401795de339bdb0e96db",
      "985d5c1a31df4758afb1ec5c8e82617d",
      "024e13a0b38a4f77a3e11e617aeb61f8",
      "c49ec6f74cd74b6e83fd6a27ba3cf994",
      "c862c4fccf6e4d44a02c7b9faadd51d2",
      "9cf75e9c35b64401b0d2bfcbfa131312",
      "63f90a48710b425083ca85c908192daf",
      "18c2d5b3a35844c9b3d5493730804a98",
      "cbcbf5375a8e4999a35491a62a3ff8d9",
      "a935a1c8c01943f78b29b4a3a68a44e6",
      "a718551d00ee47068b3d9b91aa3cb3a6",
      "632b528a48dc485dac1bd25e3a42a09d",
      "e65ffd9147a949eb8c290f894fd70f93",
      "22e99d6386f64015a3da9e71556b7ffc",
      "808846e8148a473bb2bfef925a3e5660",
      "ad052bc0522c4d0eb54481fde450d371",
      "003fe8c42f3a4becb0a1fb7a0456ab9a",
      "76c07cb2c2424954a1056a310f9d23d1",
      "000f660efd544d24b23d9a3bf08d5381",
      "b553ab5a383447f38c419d700455f304",
      "2bd7e0153225401d8982624858bd86d5",
      "ae27f921b898404aa53ecd1d4e3ee65b",
      "85d6898e574f4e83b4c8e73dba9992a2",
      "5b56e385a45945f1a4bc573bc5c93932",
      "b2fe7fb2bd4245d0ad527e0907b28892",
      "6d41e28188af439b813f513144ff0865",
      "030ebb51814d41438e5497e84c94f062",
      "2f5c296f5b214d9187c0253bf60a7d7a",
      "0ce6760e0b8f4da1b936f240096e275b",
      "83f0cfa1d9454886996cf9b0cd3a31be",
      "31505b99caee4569a6998409728630c3",
      "2d01d42a53df47598b2763c5e1148b53",
      "605616ad10fb456a94efd4f4ebbb87e8",
      "b6fcbc7be79245b08460bd4002c2d509",
      "6c8c59e80fb44e3181731cbcdc0a6c4f",
      "dc5ca9c35c9b4ec49541c756b076ca29",
      "6ba36fa2daff43e38f2fcc896a21f24d",
      "2113c56b0c63422ca0a5be20495c9559",
      "2246326f05cf48e394399c1d0081129c",
      "1a7acf08dee34ee4a66b7f2c573db938",
      "b22033b1db6f4b09b891de3c583005d1",
      "36992878c63e41d1800fea9a8e4eb168",
      "909f3f3445c441bdba43430ce25f4ba7",
      "395754054c484a48a930f0f65cd0d656",
      "60432620bc894c80a63bb3341281317d",
      "ede0c291f95d4fa8803f0b84802d449c",
      "ae2b8fd9d15e4844acb0932ef1207d4e",
      "62e4db68b6b04ebf8e1560a6fa834b14",
      "ece2d35bfc0c427a96df074c8ba750f5",
      "7417a7ea88464877be68217998ca6459",
      "139c6b13e1a14955935e06cc2dcb6c3e",
      "85973e55e52d41ebabb8de4f5dc36274",
      "684f12d177254586aa488e9da3ba0a08",
      "e8f6551d649644c5aeae629bc01cba93",
      "0c5855eda9fa448e819c838660f8960c",
      "81ff56c0911840c7a01980f29fe2a9b4",
      "8185579283554deea86462fbe4de2514",
      "c03f515f220449f1bf133eb9d401c198",
      "9902a80d75d240f88f3c135230f1a560",
      "0d6bebee00ec4dab931eab94d2877e4d",
      "e4e34754b12e4441b38460b03231cce3",
      "eccc9eab669642e09db20f1504a16d4b",
      "1f0963a29a6547938fecf984d35d7dda",
      "7696878a46124ffa9b3b869eeb94f5b2",
      "2d59fbe7eb784a2f991bb4ac9fe58dca",
      "a71a621435c24589b4adfb85a7dd5779",
      "e26d4779327c474694f3f3481e7fc525",
      "9e6b9a9aadb94f05be91b8ce704aef28",
      "c13b6f1b541549ec9dffedf2f779cf89",
      "efb44b4ac88744d5969e3f2dc1a3ca63",
      "293777886748460ab2d2d15614ac0d7d",
      "08b0513ff68649b086adf9c2df50f1c6",
      "f66aa2f8e83541a099e0ff228732558b",
      "7b79aae1b4444ed7a6afc812d242113d",
      "30f5a9ae36b64574a4212c79db48f009",
      "14328c06efd94f1d920ac558b429d9e0",
      "5743aef45686413b9f5e6a2c2401e0d1",
      "df0cd5bd5d9e46b8a7a6c1e1b0910b22",
      "b4c26d081c46403fb1d549dff889ec66",
      "33e31e52ffbe4bb5815e17c3c0077f09",
      "e4f9596d93624d6da2465bd95af067b4",
      "bdda8dd6e155497c833635a872cec90d",
      "3627b48a909d46bcbd22f791e14a239e",
      "fa2520c41d9e4ef7aac73c0c05816d3c",
      "562f9fd591384ba0ba78e413328f1944",
      "82a7694517b54cb693def75a169bb3a6",
      "d08af43fac214174a94d94681916b68b",
      "2d2c7bb0e5ed46ba9bd8b15dea84b462",
      "02bb51b12a264489a525dac9374d8de4",
      "ad4a5725b12949139d4262360d4587eb",
      "184dda44568f4ada99ce659c948a1ef2",
      "771d53f7ee36466fadafa6abd49a4e0b",
      "1d752f4b7deb4a398d8d9965b181fccd",
      "a23d75addfca48f7865c3382907e3f0a",
      "90fc02f87a294063bcac50eff822524c",
      "89693d4e899c424a846bb0eef0c9f1d5",
      "0deda00eec9f43cfaeee3447361863b1",
      "a2817916b1844dd3a12e5647a90f10be",
      "d7b2167439fc46f784262184eb5b22b2",
      "cbdfeef814b6445abde9ffc366455b93",
      "71aeb68b407f48369661b496ffc2aad2",
      "3e2297f59da649bb99c7ccbd2f221a6b",
      "4c871a583e184f049ee8b66250ae0015",
      "113ba12ffa1f4098b03a674ddc5c1178",
      "18193e72f01748a697e6b16560ee7f6b",
      "a60b0f379bce4137be360d400100939e",
      "25e99a22546e44958c288b0684f43b68",
      "3de6ba9dd95e45e2bc2327dcbc117a0a",
      "99d6b91b997e4fe084757525b7e636af",
      "f6887d5d000e48babd7f45fccc337ead",
      "1cab82c06ac74068a691cef96c4ba3a6",
      "a7dbd23d4ce0477c9367b784f059ac26",
      "5c991ec2b1f847e983bdde939251e272",
      "0d3082b8295146568a237ed0bebeb47f",
      "9372bd8c91f846f7b4e45a7eaf538673",
      "1c98e3ec757344908539584843f019f8",
      "1c136eebf28a45a28cc462a8d646318f",
      "cc1ac9444916407fbaa919352b187448",
      "fa7d1bd5089d40b8ae71ea194b199ed9",
      "be1e0fe6b66a4c039b4249a1e42a8730",
      "10a40f6c933d48c8bc9e2e76824f9ba9",
      "6bb120b0f385465a8da297bb20d4bc64",
      "22937ab32cf34dfea0b43d4b3b8f0287",
      "aed4270f403b4993b9dd93255d5a3a67",
      "c8ab24b3aa3e495181ab6a7b0f88bd01",
      "0dc11bc6bcb94622857be945e5077519",
      "73bfcb3c778d4ae29cce422480d54e93",
      "ae07a90cb3bb4ae69a84a6f66c11bc6e",
      "7d365e9678834c22bf971834c2768927",
      "0c4d7ee83fc54239b29b5be78f24fca4",
      "a792b3215abb43cd98e3b8a07bc4f438",
      "63a1f6b32f23485d978e4659d4b990b1",
      "00bf89772d3544b6b3b9c328952c8330",
      "75c7aebe7e734abcb9b686cc6156a33c",
      "32d524944ee54b7ea1fb87312918410c",
      "ffafb1a6eb3c412aac916111d0105b2e",
      "4053312ed65f48a8960f2ea36fe9787b",
      "38c8d1183c954d9ebabc7d6766b1bf68",
      "a159db8507b744adb7989ae811eeed87",
      "fde954c30b3e408e86edc5a2cd0dd471",
      "ff410dcabf6d4e128897261fb52b0b34",
      "10693371cbde4d6092182a64e9f12224",
      "cda0d16455e148cd8c0b09b6762ba6a2",
      "be55ceda1a18470392901997e14483d6",
      "60a2ec6f0ba94681aa3565454fc0456d",
      "20a22ec1a33740939644cea6ddced4b5",
      "0b43d6ab87f94734abc15ede4e7df976",
      "49a3e692816b4cd0a535ce5a95e25c21",
      "603dde4438dc4f07a3898ad62b590c07",
      "fa2ada8e49014610a034399ee4307c61",
      "96ed74f4a7414dbdbb79c7c33aa86916",
      "b0d35449bfe9449ca52a517e2da1b095",
      "ffd65c5e290044d5b56c7c1611a03154",
      "000829b51f40426392fd9329b77a5611",
      "19b028839389459b9511941dc9721f31",
      "06a88f0c03404433a68409f29ef97d97",
      "0f1276b9adff42868e7ae757d2cc0692",
      "0722a63a3a864fb0b3b283d3c151cc9b",
      "2725d37d26834b82a56720e7bb04c90a",
      "837915252ee34f75a775bf9e42a7c6d8",
      "a41e320f499a43b5b60d1c86bc2ace50",
      "4a66ff56895c436f9c1339d32d55f279",
      "5c522a48ef8144cb846a387adb02699a",
      "eecc0e8e002f4abfaccd2d5d9c0ab582",
      "6d6e76d8d23441d4894884b4750406e7",
      "e3ac032531c44675a4ecdd92b83918da",
      "29b851cc05034445a66697256975a72b",
      "8539f1cfc7cf42f49ec88f3e6d62126e",
      "66829f86528c4701935202ee075a0456",
      "2e3178ade7ea49dc951d8ec777036d6f"
     ]
    },
    "collapsed": true,
    "id": "ZV-CiKPrIFG0",
    "outputId": "31c7ba4d-6d0b-4185-c2a1-e567f6b8e413"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b464bc8bfe9147e1915ff2a8a39db199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70fb7d3ad994227a3e58c9ac9141c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0308da58442d4dd3a4b9941933cd3018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90ed7ab5ae84e9399783a13613b3fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...b-ocrLatex/tokenizer.json:   0%|          | 28.6kB / 11.4MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b977af7d5242cfb984183af85c8dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking cache directory for required files...\n",
      "Cache check failed: model-00001-of-00004.safetensors not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: tokenizer.model not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Unsloth: Preparing safetensor model files:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754c9941cf1e4764899dcf360e1002ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Unsloth: Preparing safetensor model files:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [06:08<18:26, 368.93s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf75e9c35b64401b0d2bfcbfa131312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Unsloth: Preparing safetensor model files:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [14:30<14:53, 446.76s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003fe8c42f3a4becb0a1fb7a0456ab9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Unsloth: Preparing safetensor model files:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [24:37<08:39, 519.87s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5c296f5b214d9187c0253bf60a7d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/2.72G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [27:36<00:00, 414.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: tokenizer.model not found (this is OK for non-SentencePiece models)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Unsloth: Merging weights into 16bit:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2246326f05cf48e394399c1d0081129c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7417a7ea88464877be68217998ca6459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e34754b12e4441b38460b03231cce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...0001-of-00004.safetensors:   0%|          | 16.7MB / 4.90GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Unsloth: Merging weights into 16bit:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [07:32<22:38, 452.86s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b0513ff68649b086adf9c2df50f1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3627b48a909d46bcbd22f791e14a239e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23d75addfca48f7865c3382907e3f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...0002-of-00004.safetensors:   0%|          |  601kB / 4.92GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Unsloth: Merging weights into 16bit:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [14:00<13:48, 414.28s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18193e72f01748a697e6b16560ee7f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c98e3ec757344908539584843f019f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73bfcb3c778d4ae29cce422480d54e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...0003-of-00004.safetensors:   0%|          | 1.20MB / 5.00GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Unsloth: Merging weights into 16bit:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [22:05<07:26, 446.57s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c8d1183c954d9ebabc7d6766b1bf68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603dde4438dc4f07a3898ad62b590c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837915252ee34f75a775bf9e42a7c6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...0004-of-00004.safetensors:   1%|          | 25.2MB / 2.72GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [26:38<00:00, 399.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merge process complete. Saved to `/content/wizardoftrap/qwen-VL-8b-ocrLatex`\n"
     ]
    }
   ],
   "source": [
    "model.push_to_hub_merged(\n",
    "        \"wizardoftrap/qwen-VL-8b-ocrLatex\", tokenizer,\n",
    "        token = \"\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOqRjSuvYBbo9v07r5heV9o",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
